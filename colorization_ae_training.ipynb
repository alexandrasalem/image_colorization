{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colorization_ae_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt_BgWTBgD_m"
      },
      "source": [
        "Training notebook for:\n",
        "\n",
        "Model 1: AE without fusion\n",
        "\n",
        "Model 2: AE with fusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OhrDL5xjv6o",
        "outputId": "424c92d8-7075-45d8-a124-faa4ac6ff5e2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaoQCNAeead2"
      },
      "source": [
        "Loading libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXJRzxofMBAa"
      },
      "source": [
        "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, Reshape, concatenate, Layer, Flatten, Dense\n",
        "from keras.layers.core import RepeatVector\n",
        "from keras.models import Sequential, Model\n",
        "from keras.utils import plot_model\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from keras import Input, datasets, metrics, optimizers\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input, decode_predictions\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from skimage.color import rgb2lab, lab2rgb, grey2rgb, rgb2grey\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave, imshow, imread\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "import time\n",
        "from cv2 import resize, INTER_AREA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAtUKAhZyH0E",
        "outputId": "ec57525d-25a7-4d32-9f3c-3f9ec7c5a7ef"
      },
      "source": [
        "inception = InceptionResNetV2(weights='imagenet', include_top=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n",
            "225214464/225209952 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a8VY3HTeciH"
      },
      "source": [
        "Data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pajj-KV7yRCW"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"Generates data for Keras\n",
        "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
        "    \"\"\"\n",
        "    def __init__(self, list_IDs, image_path,\n",
        "                 to_fit=True, batch_size=32, dim=(256, 256), shuffle=True, fusion=False, fusion_path='fusion/'):\n",
        "        \"\"\"Initialization\n",
        "\n",
        "        :param list_IDs: list of all 'label' ids to use in the generator\n",
        "        :param image_path: path to images location\n",
        "        :param to_fit: True to return X and y, False to return X only\n",
        "        :param batch_size: batch size at each iteration\n",
        "        :param dim: tuple indicating image dimension\n",
        "        :param shuffle: True to shuffle label indexes after every epoch\n",
        "        :param fusion: True to return X and X_fusion, False returns X\n",
        "        \"\"\"\n",
        "        self.list_IDs = list_IDs\n",
        "        self.image_path = image_path\n",
        "        self.to_fit = to_fit\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.shuffle = shuffle\n",
        "        self.fusion = fusion\n",
        "        self.fusion_path = fusion_path\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch\n",
        "\n",
        "        :return: number of batches per epoch\n",
        "        \"\"\"\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generate one batch of data\n",
        "\n",
        "        :param index: index of the batch\n",
        "        :return: X and y when fitting. X only when predicting\n",
        "        \"\"\"\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X = self._generate_X(list_IDs_temp)\n",
        "        if self.to_fit:\n",
        "            y = self._generate_y(list_IDs_temp)\n",
        "            return X, y\n",
        "        else:\n",
        "            return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Updates indexes after each epoch\n",
        "\n",
        "        \"\"\"\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def _generate_X(self, list_IDs_temp):\n",
        "        \"\"\"Generates data containing batch_size images\n",
        "\n",
        "        :param list_IDs_temp: list of label ids to load\n",
        "        :return: batch of images\n",
        "        \"\"\"\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, 1))\n",
        "        if self.fusion:\n",
        "          X_fusion = np.empty((self.batch_size, 1000))\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            X[i,] = self._load_lab_grayscale_image(self.image_path + ID)\n",
        "            if self.fusion:\n",
        "              X_fusion[i,] = self._load_fusion(self.fusion_path + ID)\n",
        "\n",
        "        if self.fusion:\n",
        "          return [X, X_fusion]\n",
        "        else:\n",
        "          return X\n",
        "\n",
        "    def _generate_y(self, list_IDs_temp):\n",
        "        \"\"\"Generates data containing batch_size masks\n",
        "\n",
        "        :param list_IDs_temp: list of label ids to load\n",
        "        :return: batch if masks\n",
        "        \"\"\"\n",
        "        y = np.empty((self.batch_size, *self.dim, 2))\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            y[i,] = self._load_lab_color_image(self.image_path + ID)\n",
        "\n",
        "        return y\n",
        "\n",
        "    def _load_lab_grayscale_image(self, image_path):\n",
        "      img = imread(image_path)\n",
        "      img = img*(1.0/255)\n",
        "      img = resize(img, (256, 256))\n",
        "      if img.shape == (256, 256):\n",
        "        img = grey2rgb(img)\n",
        "      img = rgb2lab(img)\n",
        "      img =(img[:,:,0]).reshape(img[:,:,0].shape+(1,))\n",
        "      return img\n",
        "\n",
        "    def _load_fusion(self, image_path):\n",
        "      with open(image_path, 'rb') as f:\n",
        "          embed = np.load(f)\n",
        "          return embed \n",
        "\n",
        "    def _load_lab_color_image(self, image_path):\n",
        "      img = imread(image_path)\n",
        "      img = img*(1.0/255)\n",
        "      img = resize(img, (256, 256))\n",
        "      if img.shape == (256, 256):\n",
        "        img = grey2rgb(img)\n",
        "      img = rgb2lab(img)\n",
        "      img = img[:,:,1:]*(1.0/128)\n",
        "      return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSdRZf98eeyU"
      },
      "source": [
        "Loading data list, making inception-resnet-v2 representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycK91zH6dtex"
      },
      "source": [
        "with open(\"places_sample_train.txt\") as f:\n",
        "  train_list = f.readlines()\n",
        "train_list = [x[:-1] for x in train_list]\n",
        "\n",
        "with open(\"places_sample_val.txt\") as f:\n",
        "  val_list = f.readlines()\n",
        "val_list = [x[:-1] for x in val_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQSKn6MKzQVu"
      },
      "source": [
        "!mkdir fusion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smv3avSLyeyO"
      },
      "source": [
        "for image in val_list:\n",
        "      img = imread('./gdrive/MyDrive/val_256/'+ image)\n",
        "      img = img*(1.0/255)\n",
        "      img = grey2rgb(rgb2grey(img))\n",
        "      img = resize(img, (299, 299))\n",
        "      img = preprocess_input(img)\n",
        "      img = img.reshape((1,) + img.shape)\n",
        "      embed = inception.predict(img)\n",
        "      with open('./fusion/' + image, 'wb') as f:\n",
        "          np.save(f, embed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF94GSU7dznA"
      },
      "source": [
        "for image in train_list:\n",
        "      img = imread('./gdrive/MyDrive/val_256/'+ image)\n",
        "      img = img*(1.0/255)\n",
        "      img = grey2rgb(rgb2grey(img))\n",
        "      img = resize(img, (299, 299))\n",
        "      img = preprocess_input(img)\n",
        "      img = img.reshape((1,) + img.shape)\n",
        "      embed = inception.predict(img)\n",
        "      with open('./fusion/' + image, 'wb') as f:\n",
        "          np.save(f, embed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zh_THarelWz"
      },
      "source": [
        "Model 1 AE below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh6Du8VSYXPv"
      },
      "source": [
        "#Vanilla Autoencoder\n",
        "encoder_input = Input(\n",
        "    shape=(256, 256, 1,), name=\"input\"\n",
        ") \n",
        "\n",
        "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
        "encoder_output = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(128, (3, 3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3, 3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "\n",
        "decoder_output = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(32, (3, 3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "model = Model(inputs=encoder_input, outputs=decoder_output)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mSuPJ3CeoAT"
      },
      "source": [
        "Training model 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5bQ9NDzeTYR"
      },
      "source": [
        "image_path = \"gdrive/MyDrive/val_256/\"\n",
        "train_datagen = DataGenerator(train_list, image_path, fusion = False, batch_size = 100)\n",
        "val_datagen = DataGenerator(val_list, image_path, fusion = False, batch_size = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEazglLFeQeN"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=7)\n",
        "mc = ModelCheckpoint('gdrive/MyDrive/colorize_autoencoder_10000_50.model', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "model.fit(train_datagen, validation_data = val_datagen, epochs=100, callbacks=[es, mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYWoCxDReph8"
      },
      "source": [
        "Model 2 AE with fusion below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqpFWD175KWj"
      },
      "source": [
        "# Vanilla Autoencoder + inception-resnet-v2\n",
        "\n",
        "encoder_input = Input(\n",
        "    shape=(256, 256, 1,), name=\"input\"\n",
        ") \n",
        "\n",
        "embed_input = Input(shape=(1000,))\n",
        "\n",
        "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
        "encoder_output = Conv2D(128, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(128, (3, 3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3, 3), activation='relu', padding='same', strides=2)(encoder_output)\n",
        "encoder_output = Conv2D(512, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "encoder_output = Conv2D(256, (3, 3), activation='relu', padding='same')(encoder_output)\n",
        "\n",
        "fusion_output = RepeatVector(32 * 32)(embed_input) \n",
        "fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
        "fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
        "fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n",
        "\n",
        "decoder_output = Conv2D(128, (3, 3), activation='relu', padding='same')(fusion_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(64, (3, 3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "decoder_output = Conv2D(32, (3, 3), activation='relu', padding='same')(decoder_output)\n",
        "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "\n",
        "model = Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRRbaO0zeslP"
      },
      "source": [
        "Training model 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc0nYwHUeLE8"
      },
      "source": [
        "image_path = \"gdrive/MyDrive/val_256/\"\n",
        "train_datagen = DataGenerator(train_list, image_path, fusion = True, batch_size = 100)\n",
        "val_datagen = DataGenerator(val_list, image_path, fusion = True, batch_size = 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX2kwDRx5Nij"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=7)\n",
        "mc = ModelCheckpoint('gdrive/MyDrive/colorize_autoencoder_fusion_10000_50.model', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "model.fit(train_datagen, validation_data = val_datagen, epochs=100, callbacks=[es, mc])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}